# Debunking the Chessboard: Confronting GPTs Against Chess Engines to Estimate Elo Ratings and Assess Legal Move Abilities

Des affirmations récentes ont suggéré que les modèles de langage de grande taille (LLMs), tels que les variantes de GPT, pourraient exceller aux échecs, allant même jusqu'à surpasser une majorité de joueurs humains ou à produire systématiquement des coups légaux. Cette étude examine systématiquement ces assertions en confrontant différents modèles GPT à des moteurs d'échecs établis, dans diverses conditions expérimentales. Le principal défi réside dans l'assurance d'une reproductibilité robuste, en contrôlant avec soin les invites (prompts), les paramètres de jeu et les variantes des modèles, afin d'évaluer avec précision les capacités de génération de coups légaux ainsi que les classements Elo approximatifs de ces systèmes. Ce travail met en évidence que certaines stratégies de fine-tuning orientées vers les interactions conversationnelles peuvent en réalité réduire les performances sur une tâche bien définie et régie par des règles, comme les échecs. [Ici, vous ajouteriez les résultats clés ou les informations principales obtenues après vos expériences.]

